---
format: 
  html:
    self-contained: true    
    df-print: paged
---

![](images/World_Happiness_Report_23.png){fig-align="center"}

# INF 385T.9 - Data Wrangling Final Project: Does Positive Pop Music Portend Positive Attitudes?

# Python Pandas

## Load packages

```{r}
library(reticulate)
#reticulate::py_install("pandas")
```

```{python}
import pandas as pd
from io import StringIO
import numpy as np
```

## Dataset 1 - World Happiness Report (WHR)

```{python}

## Load World Happiness Report - 2023
WHR23 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/WHR23.csv')


## Show all columns of WHR23 
print(WHR23.columns)
```

```{python}

## Keep only the key variables from the World Happiness Report: 
## Country, Ladder Score (Happiness score), GDP per Capita, 
## Social Support, Healthy life expectancy, Freedom to make life choices, and Generosity
## Freedom to make life choices, and Generosity
WHR23 = WHR23.filter(items = ['Country name', 
                              'Ladder score',
                              'Logged GDP per capita',
                              'Social support', 
                              'Healthy life expectancy',
                              'Freedom to make life choices', 
                              'Generosity'])

print(WHR23.columns)
```

```{python}

## Standardize column names using 'snake_case' for 
## easier manipulation and cleaner referencing
Happiness_report_23 = WHR23.rename(columns = {'Country name': 'country_name',
                                              'Ladder score': 'happiness_score',
                                              'Logged GDP per capita': 'gdp_wellbeing',
                                              'Social support': 'social_support',
                                              'Healthy life expectancy': 'life_exp',
                                              'Freedom to make life choices': 'freedom',
                                              'Generosity': 'generosity'})
                                              
print(Happiness_report_23)
print(Happiness_report_23.columns)
```

## Dataset 2 - 2023 Universal Top Spotify Songs

References:

<https://www.geeksforgeeks.org/python/python-remove-spaces-from-a-string/>

<https://www.geeksforgeeks.org/python/python-string-lower/>

[https://pandas.pydata.org/docs/user_guide/text.html](https://pandas.pydata.org/docs/user_guide/text.html?utm_source=chatgpt.com){.uri}

[https://stackoverflow.com/questions/29761915/case-insensitive-pandas-dataframe-merge](https://stackoverflow.com/questions/29761915/case-insensitive-pandas-dataframe-merge?utm_source=chatgpt.com){.uri}

```{python}

## Load global top spotify song (2023) dataset
universal_top_spotify_songs_2023 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/universal_top_spotify_songs_2023.csv')


## Show all columns of universal_top_spotify_songs_2023 
print(universal_top_spotify_songs_2023.columns)
```

```{python}

## Select the song title, artist, country, and the 
## 5 main audio features (danceability, energy, loudness, valence, tempo)
spotify_2023 = universal_top_spotify_songs_2023.filter(items = ['name', 
                                                                'artists',
                                                                'country',
                                                                'danceability', 
                                                                'energy',
                                                                'loudness', 
                                                                'valence',
                                                                'tempo'])



## Rename name column to title 
spotify_2023 = spotify_2023.rename(columns = {'name': 'title'})


print(spotify_2023)
print(spotify_2023.columns)
```

```{python}

## Clean the 'artists' and 'title' columns for joining:
## 1. Convert to lowercase and trim whitespace 
## 2. Extract only the primary artist using 'word' function.
## 3. Remove rows with missing country data for reliable aggregation.
global_spotify_2023 = (
  spotify_2023
    .assign(artist = lambda df_: df_['artists'].str.split(',').str[0].str.strip().str.lower(),
            title = lambda df_: df_['title'].str.strip().str.lower())
    .drop(columns = ['artists'])
    .dropna(subset=['country'])
    
)


## Rearrange columns 
global_spotify_2023 = global_spotify_2023[['title', 'artist', 'country', 'danceability', 'energy', 'loudness', 'valence', 'tempo']]


print(global_spotify_2023)
print(global_spotify_2023.columns)
```

## Dataset 3 - World Dataset

```{python}

## Load the world_data_2023
world_data_2023 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/world_data_2023.csv')


print(world_data_2023.columns)
```

```{python}

## Create a 'abbreviation_table' containing only Country names and their 
## corresponding Abbreviation for later joining with the Spotify dataset
abbreviation_table = world_data_2023.filter(items = ['Country', 'Abbreviation'])


abbreviation_table
```

## Dataset 4 - Weekly Top Spotify Chart (10/16/2025) (Kworb)

References:

<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html>

### New Zealand Dataset

```{python}

## Load Ireland's weekly chart for 10-16-2025
new_zealand_25 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/10_16_25_new_zealand.csv')


print(new_zealand_25.columns)
```

```{python}

## Remove all columns except for the 'Artist.and.Title' column.
## Separate artist and song title from the 'Artist.and.Title' column
## 
new_zealand_filtered = (
  new_zealand_25
  .filter(items = ['Artist and Title'])
  .assign(Artist = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[0],
          Title = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[1])
  .drop(columns = ['Artist and Title'])  

)
  

print(new_zealand_filtered)
print(new_zealand_filtered.columns)
```

```{python}

## Extract only the first artist
## Clean the 'artists' and 'title' columns for joining:
## Convert to lowercase and trim whitespace
new_zealand_filtered_2025 = (
  new_zealand_filtered
  .assign(Artist = lambda df_: df_['Artist'].str.split(',',  n = 1).str[0].str.strip().str.lower(),
          Title = lambda df_: df_['Title'].str.strip().str.lower())  

)
  
new_zealand_filtered_2025
```

### South Korea Dataset

```{python}

## Import South Korea's weekly chart for 10-16-2025
south_korea_2025 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/10_16_25_korea.csv')


print(south_korea_2025)
print(south_korea_2025.columns)
```

```{python}

## Remove all columns except for the 'Artist.and.Title' column.
## Separate artist and song title from the 'Artist.and.Title' column
south_korea_filtered = (
  south_korea_2025
  .filter(items = ['Artist and Title'])
  .assign(Artist = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[0],
          Title = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[1])
  .drop(columns = ['Artist and Title'])  

)
  

south_korea_filtered
```

```{python}

## Extract only the first artist
## Clean the 'artists' and 'title' columns for joining:
## Convert to lowercase and trim whitespace
south_korea_filtered_2025 = (
  south_korea_filtered
  .assign(Artist = lambda df_: df_['Artist'].str.split(',',  n = 1).str[0].str.strip().str.lower(),
          Title = lambda df_: df_['Title'].str.strip().str.lower())  

)
  

south_korea_filtered_2025
```

### USA Dataset

```{python}

## Import USA's weekly chart for 10-16-2025
usa_25 = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/10_16_25_usa.csv')


print(usa_25)
print(usa_25.columns)
```

```{python}

## Extract only the Artist.and.Title column
## Separate artist and song title from the Artist.and.Title column
usa_filtered = (
  usa_25
  .filter(items = ['Artist and Title'])
  .assign(Artist = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[0],
          Title = lambda df_: df_['Artist and Title'].str.split('-',  n = 1).str[1])
  .drop(columns = ['Artist and Title'])  

)
  

usa_filtered
```

```{python}

## Extract only the first artist
## Clean the 'artists' and 'title' columns for joining:
## Convert to lowercase and trim whitespace
usa_filtered_2025 = (
  usa_filtered
  .assign(Artist = lambda df_: df_['Artist'].str.split(',',  n = 1).str[0].str.strip().str.lower(),
          Title = lambda df_: df_['Title'].str.strip().str.lower())   

)
  

usa_filtered_2025
```

## Dataset 5 - Universal Top Spotify Songs (Kaggle)

This dataset was last updated on June 11, 2025.

```{python}

## Import the Universal Top Spotify Songs dataset
universal_top_spotify_songs = pd.read_csv('/Users/Jaykay/Desktop/INF 385T.9 - Data Wrangling/Final Project Data/universal_top_spotify_songs.csv')


print(universal_top_spotify_songs)
print(universal_top_spotify_songs.columns)
```

```{python}

## Select 'name', 'artists', 'country', 'danceability' ,'energy', 
## 'loudness', 'valence', and 'tempo' columns only
## Extract only the first artist
## Clean the 'artists' and 'title' columns for joining:
## Convert to lowercase and trim whitespace
spotify_2025_py_cleaned = (
  universal_top_spotify_songs
  .assign(artist = lambda df_: df_['artists'].astype(str).str.split(',').str[0].str.strip().str.lower())
  .assign(title = lambda df_: df_['name'].astype(str).str.strip().str.lower())
  .filter(items = ['title', 'artist', 'danceability', 'energy', 'loudness', 'valence', 'tempo'])

)


print(spotify_2025_py_cleaned)
print(spotify_2025_py_cleaned.columns)
```

## Joining Dataset 2 and 3 - Replacing Abbreviations with Full Country Names

```{python}

## Join Spotify data with the abbreviation table to replace country codes with 
## full Country names using columns with abbreviations
## Drop 'abbreviation' column
## Relocate the 'country' column to the front
## Remove any unmatched rows
spotify_global_2023_matched = (

  global_spotify_2023
  .merge(abbreviation_table,
         left_on = ['country'],
         right_on = ['Abbreviation'],
         how = 'left')
  .drop(columns = ['country', 
                   'Abbreviation'])
  .dropna(subset=['Country'])

)


print(spotify_global_2023_matched)
print(spotify_global_2023_matched.columns)
```

## Aggregating Mean Audio Features by Country for the 2023 Spotify Dataset (Danceability, Energy, Loudness, Valence, Tempo)

```{python}

## Calculate mean of all five audio features (danceability, energy, loudness, valence, tempo)
## for each Country in the spotify_global_2023_matched dataset
spotify_global_2023_avg = (
  spotify_global_2023_matched
    .groupby('Country')
    .agg(danceability_avg = ('danceability', 'mean'),
         energy_avg = ('energy', 'mean'),
         loudness_avg = ('loudness', 'mean'),
         valence_avg = ('valence', 'mean'),
         tempo_avg = ('tempo', 'mean'))

)


print(spotify_global_2023_avg)
print(spotify_global_2023_avg.columns)
```

## Joining Universal Song Data with Country-Specific Charts (2025)

References:

<https://stackoverflow.com/questions/60006995/round-while-groupping-by-in-pandas-with-agg-function?utm_source=chatgpt.com>

### **New Zealand** Dataset

```{python}

## Join New Zealand dataframe and 2025 Spotify dataframe
new_zealand_2025_matched = new_zealand_filtered_2025.merge(
    spotify_2025_py_cleaned,
    left_on = ['Title', 'Artist'],
    right_on = ['title', 'artist'],
    how = 'left'

)


print(new_zealand_2025_matched)
print(new_zealand_2025_matched.columns)
```

```{python}

## Clean the joined 2025 dataset:
## Drop title and artist columns from new_zealand_2025_matched
## Remove duplicate song entries
## Drop rows where audio features are missing
## Add Country and year column for aggretation and future analysis
new_zealand_2025_matched_cleaned = (
  new_zealand_2025_matched
    .drop(columns = ['title', 'artist'])
    .drop_duplicates(subset = ['Title', 'Artist'])
    .dropna(subset = ['danceability'])
    .assign(Country = "New Zealand",
            year = 2025)
    .reset_index(drop = True) 
 
)


print(new_zealand_2025_matched_cleaned)
print(new_zealand_2025_matched_cleaned.columns)
```

```{python}

## Calculate mean values for all audio metrics
## Add Country and year columns as identifiers
new_zealand_2025_avg = (
  new_zealand_2025_matched_cleaned
    .groupby('Country')    
    .agg(danceability_avg = ('danceability', 'mean'),
         energy_avg = ('energy', 'mean'),
         loudness_avg = ('loudness', 'mean'),
         valence_avg = ('valence', 'mean'),
         tempo_avg = ('tempo', 'mean'),
         year = ('year', 'mean'))   ## Every year value is 2025; this line was added for uniformity
    .reset_index()  # Need the Country as its own column

)


print(new_zealand_2025_avg)
```

### South Korea Dataset

```{python}

## Join South Korea dataframe and 2025 Spotify dataframe
south_korea_2025_matched = south_korea_filtered_2025.merge(
    spotify_2025_py_cleaned,
    left_on = ['Title', 'Artist'],
    right_on = ['title', 'artist'],
    how = 'left'
    
)


print(south_korea_2025_matched)
print(south_korea_2025_matched.columns)
```

```{python}

## Clean the joined 2025 dataset:
## Drop title and artist columns from south_korea_2025_matched
## Remove duplicate song entries
## Drop rows where audio features are missing
## Add Country and year column for aggretation and future analysis
south_korea_2025_matched_cleaned = (
  south_korea_2025_matched
    .drop(columns = ['title', 'artist'])
    .drop_duplicates(subset = ['Title', 'Artist'])
    .dropna(subset = ['danceability'])
    .assign(Country = "South Korea",
            year = 2025)
    .reset_index(drop=True)  ## Need the Country as its own column

)


print(south_korea_2025_matched_cleaned)
print(south_korea_2025_matched_cleaned.columns)
```

```{python}

## Calculate mean values for all audio metrics
## Add Country and year columns as identifiers
south_korea_2025_avg = (
  south_korea_2025_matched_cleaned
    .groupby('Country')
    .agg(danceability_avg = ('danceability', 'mean'),
         energy_avg = ('energy', 'mean'),
         loudness_avg = ('loudness', 'mean'),
         valence_avg = ('valence', 'mean'),
         tempo_avg = ('tempo', 'mean'),
         year = ('year', 'mean'))   ## Every year value is 2025; this line was added for uniformity)
    .reset_index()   # Need the Country as its own column

)


print(south_korea_2025_avg)
```

### USA Dataset

```{python}

## Join United States dataframe and updated Spotify dataframe
## Left join to keep all the rows of left dataframe
usa_2025_matched = usa_filtered_2025.merge(
    spotify_2025_py_cleaned,
    left_on = ['Title', 'Artist'],
    right_on = ['title', 'artist'],
    how = 'left'
)


print(usa_2025_matched)
print(usa_2025_matched.columns)
```

```{python}

## Clean the joined 2025 dataset:
## Drop title and artist columns from usa_2025_matched
## Remove duplicate song entries
## Drop rows where audio features are missing
## Add Country and year column for aggretation and future analysis
usa_2025_matched_cleaned = (
  usa_2025_matched
    .drop(columns = ['title', 'artist'])
    .drop_duplicates(subset = ['Title', 'Artist'])
    .dropna(subset = ['danceability'])
    .assign(Country = "United States",
            year = 2025)
    .reset_index(drop = True)    ## No longer need the old index

)


print(usa_2025_matched_cleaned)
print(usa_2025_matched_cleaned.columns)
```

```{python}

## Calculate mean values for all audio metrics
## Add Country and year columns as identifiers
usa_2025_avg = (
  usa_2025_matched_cleaned
    .groupby('Country')
    .agg(danceability_avg = ('danceability', 'mean'),
         energy_avg = ('energy', 'mean'),
         loudness_avg = ('loudness', 'mean'),
         valence_avg = ('valence', 'mean'),
         tempo_avg = ('tempo', 'mean'),
         year = ('year', 'mean'))     ## Every year value is 2025; this line was added for uniformity
    .reset_index()   # Need the Country as its own column

)


print(usa_2025_avg)
```

## Correlation Studies

References:

<https://seaborn.pydata.org/generated/seaborn.heatmap.html>

<https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html>

<https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xticks.html>

<https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.yticks.html>

<https://www.datacamp.com/tutorial/seaborn-heatmaps>

<https://www.geeksforgeeks.org/python/change-the-order-of-a-pandas-dataframe-columns-in-python/>

<https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tight_layout.html>

<https://matplotlib.org/stable/users/explain/colors/colormaps.html>

### Import Libraries for Plots

```{python}
import seaborn as sns
import matplotlib.pyplot as plt
```

### Preparing Datasets for Correlation Analysis

```{python}

## Combine the spotify_global_2023_avg dataset with Happiness_report_23 
## Drop any rows where a happiness score is not available
happiness_spotify_2023_pd = (
  spotify_global_2023_avg
    .merge(Happiness_report_23,
           left_on = ['Country'],
           right_on = ['country_name'],
           how = 'left')
    .dropna(subset=['happiness_score'])

)


print(happiness_spotify_2023_pd)
print(happiness_spotify_2023_pd.columns)
```

### Analyzing Correlations in the Top 10 Happiness Score Countries

```{python}

## Select top 10 countries with highest happiness_score
## Rearrange columns for more intuitive understanding
top_happiness_score_spotify_23 = (
  happiness_spotify_2023_pd
  .sort_values('happiness_score', ascending = False)
  .head(10)
  [['country_name', 'danceability_avg', 'energy_avg', 'loudness_avg', 'valence_avg',
       'tempo_avg', 'happiness_score', 'gdp_wellbeing',
       'social_support', 'life_exp', 'freedom', 'generosity']]
  .reset_index(drop = True)    ## No longer need the old index
  
)


print(top_happiness_score_spotify_23)
print(top_happiness_score_spotify_23.columns)
```

```{python}

## Drop the country_name column for correltion analysis
top_happiness_score_spotify_23_cleaned = top_happiness_score_spotify_23.drop(columns = ['country_name'])
  

print(top_happiness_score_spotify_23_cleaned)
print(top_happiness_score_spotify_23_cleaned.columns)
```

```{python}

## Correlation analysis
top_happiness_countries_23_corr = top_happiness_score_spotify_23_cleaned.corr()

print(top_happiness_countries_23_corr)
```

```{python}

## Create a heatmap using Seaborn
plt.figure()

sns.heatmap(top_happiness_countries_23_corr, 
            vmin = -1.0,
            vmax = 1.0,
            center = 0.0,
            annot =True,
            cmap = 'bwr_r',
            cbar_kws = {'label': 'Correlation'},
            square = True, 
            linewidths = 0.4,
            annot_kws={'size': 6})

## Rotate x-axis labels
plt.xticks(rotation = 45, ha = 'right', fontsize = 6)

## Rotate y-axis labels
plt.yticks(va = 'center', fontsize = 6)

## Create a title for the heatmap 
plt.title("Correlations for the Top 10 Happiest Countries")

plt.tight_layout()
plt.show()
```

### Analyzing Correlations in the Bottom 10 Happiness Score Countries

```{python}

## Select top 10 countries with highest happiness_score
## Rearrange columns for more intuitive understanding
bottom_happiness_score_spotify_23 = (
  happiness_spotify_2023_pd
  .sort_values('happiness_score', ascending = True)
  .head(10)
  [['country_name', 'danceability_avg', 'energy_avg', 'loudness_avg', 'valence_avg',
       'tempo_avg', 'happiness_score', 'gdp_wellbeing',
       'social_support', 'life_exp', 'freedom', 'generosity']]
  .reset_index(drop = True)     ## No longer need the old index

)

print(bottom_happiness_score_spotify_23)
print(bottom_happiness_score_spotify_23.columns)
```

```{python}

## Drop the country_name column for correltion analysis
bottom_happiness_score_spotify_23_cleaned = bottom_happiness_score_spotify_23.drop(columns = ['country_name'])
  

print(bottom_happiness_score_spotify_23_cleaned)
print(bottom_happiness_score_spotify_23_cleaned.columns)
```

```{python}

## Correlation analysis
bot_happiness_countries_23_corr = bottom_happiness_score_spotify_23_cleaned.corr()

print(bot_happiness_countries_23_corr)
```

```{python}

## Create a heatmap using Seaborn
plt.figure()

sns.heatmap(bot_happiness_countries_23_corr, 
            vmin = -1.0,
            vmax = 1.0,
            center = 0.0,
            annot =True,
            cmap = 'bwr_r',
            cbar_kws = {'label': 'Correlation'},
            square = True,
            linewidths = 0.4,
            annot_kws={'size': 6})

## Rotate x-axis labels
plt.xticks(rotation = 45, ha = 'right', fontsize = 6)

## Rotate y-axis labels
plt.yticks(va = 'center', fontsize = 6)

## Create a title for the heatmap 
plt.title("Correlations for the Bottom 10 Happiest Countries")

plt.tight_layout()
plt.show()
```

## Comparing 2023 and 2025 Spotify Dataset

Since 2025 Happiness Report is not available yet, we will compare the average of music analytic components and note if there's any changes.

### New Zealand

```{python}

## Filter New Zealand's data from the global 2023 averages
## Add a 'year' column as an identifier 
new_zealand_2023 = (
  spotify_global_2023_avg
  .query("Country == 'New Zealand'")
  .assign(year = 2023)
  .reset_index()   # Need the Country as its own column
  
)

print(new_zealand_2023)
print(new_zealand_2023.columns)
```

```{python}

## Combine 2023 and 2025 New Zealand data into a single table
new_zealand_spotify_combined = pd.concat([new_zealand_2023, new_zealand_2025_avg])


## Melt the table along the Country and year
new_zealand_spotify_combined_melt = new_zealand_spotify_combined.melt(
  id_vars = ['Country', 'year'],
  value_vars=['danceability_avg', 'energy_avg', 'loudness_avg', 'valence_avg', 'tempo_avg'],
  var_name = 'Metrics',
  value_name = 'value')  
                                                                 
                                                                 
print(new_zealand_spotify_combined_melt)
```

### South Korea

```{python}

## Filter South Korea's data from the global 2023 averages
## Add a 'year' column as an identifier 
south_korea_2023 = (
  spotify_global_2023_avg
  .query("Country == 'South Korea'")
  .assign(year = 2023)
  .reset_index()   # Need the Country as its own column
  
)

print(south_korea_2023)
print(south_korea_2023.columns)
```

```{python}

## Concat 2023 and 2025 South Korea data into one table
south_korea_spotify_combined = pd.concat([south_korea_2023, south_korea_2025_avg])


## Melt the table along the Country and year
south_korea_spotify_combined_melt = south_korea_spotify_combined.melt(
  id_vars = ['Country', 'year'],
  value_vars=['danceability_avg', 'energy_avg', 'loudness_avg', 'valence_avg', 'tempo_avg'],
  var_name = 'Metrics',
  value_name = 'value')  
                                                                 
                                                                 
print(south_korea_spotify_combined_melt)
```

### USA

```{python}

## Filter USA data from the global 2023 averages
## Add a 'year' column as an identifier 
usa_2023 = (
  spotify_global_2023_avg
  .query("Country == 'United States'")
  .assign(year = 2023)
  .reset_index()   # Need the Country as its own column
  
)

print(usa_2023)
print(usa_2023.columns)
```

```{python}

## Concat 2023 and 2025 New Zealand data into one table
usa_spotify_combined = pd.concat([usa_2023, usa_2025_avg])


## Melt the table along the Country and year
usa_spotify_combined_melt = usa_spotify_combined.melt(
  id_vars = ['Country', 'year'],
  value_vars=['danceability_avg', 'energy_avg', 'loudness_avg', 'valence_avg', 'tempo_avg'],
  var_name = 'Metrics',
  value_name = 'value')  
                                                                 
                                                                 
print(usa_spotify_combined_melt)
```
